{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3aa0b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "한국어 -> 일본어 : ['こんにちは、ありがとうございます、元気です、また会いましょう。']\n",
      "한국어 -> 영어 : ['Hello, thank you, it’s good, we’ll see you again.']\n",
      "일본어 -> 한국어 : ['안녕하세요, 고마워요, 잘 지내고 다시 만나겠습니다.']\n",
      "영어 -> 한국어 : ['안녕하세요, 감사합니다, 좋은 일입니다, 우리는 다시 당신을 볼 것입니다.']\n"
     ]
    }
   ],
   "source": [
    "from transformers import M2M100ForConditionalGeneration, M2M100Tokenizer\n",
    "\n",
    "ko_text = \"안녕하세요, 감사해요, 잘 있어요, 다시 만나요\"\n",
    "\n",
    "\n",
    "model = M2M100ForConditionalGeneration.from_pretrained(\"facebook/m2m100_418M\")\n",
    "tokenizer = M2M100Tokenizer.from_pretrained(\"facebook/m2m100_418M\")\n",
    "\n",
    "tokenizer.src_lang = \"ko\"\n",
    "encoded_hi = tokenizer(ko_text, return_tensors=\"pt\")\n",
    "generated_tokens = model.generate(**encoded_hi, forced_bos_token_id=tokenizer.get_lang_id(\"ja\"))\n",
    "kor_to_jap = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
    "print('한국어 -> 일본어 :', kor_to_jap)\n",
    "\n",
    "\n",
    "tokenizer.src_lang = \"ko\"\n",
    "encoded_zh = tokenizer(ko_text, return_tensors=\"pt\")\n",
    "generated_tokens = model.generate(**encoded_zh, forced_bos_token_id=tokenizer.get_lang_id(\"en\"))\n",
    "kor_to_eng = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
    "print('한국어 -> 영어 :', kor_to_eng)\n",
    "\n",
    "tokenizer.src_lang = \"ja\"\n",
    "encoded_hi = tokenizer(kor_to_jap, return_tensors=\"pt\")\n",
    "generated_tokens = model.generate(**encoded_hi, forced_bos_token_id=tokenizer.get_lang_id(\"ko\"))\n",
    "kor_to_jap = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
    "print('일본어 -> 한국어 :', kor_to_jap)\n",
    "\n",
    "tokenizer.src_lang = \"en\"\n",
    "encoded_hi = tokenizer(kor_to_eng, return_tensors=\"pt\")\n",
    "generated_tokens = model.generate(**encoded_hi, forced_bos_token_id=tokenizer.get_lang_id(\"ko\"))\n",
    "kor_to_jap = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
    "print('영어 -> 한국어 :', kor_to_jap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18ed7a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* Running on public URL: https://4b533e89781be58a0a.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://4b533e89781be58a0a.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "📖 다국어 번역기 (Gradio + M2M100)\n",
    "- transformers의 facebook/m2m100_418M 모델 사용\n",
    "- Gradio로 웹 UI 구성\n",
    "\"\"\"\n",
    "\n",
    "from transformers import M2M100ForConditionalGeneration, M2M100Tokenizer\n",
    "import gradio as gr\n",
    "\n",
    "def load_model():\n",
    "    \"\"\"모델과 토크나이저 로드\"\"\"\n",
    "    model = M2M100ForConditionalGeneration.from_pretrained(\"facebook/m2m100_418M\")\n",
    "    tokenizer = M2M100Tokenizer.from_pretrained(\"facebook/m2m100_418M\")\n",
    "    return model, tokenizer\n",
    "\n",
    "# 1. 모델 초기화\n",
    "model, tokenizer = load_model()\n",
    "\n",
    "# 2. 지원 언어 매핑\n",
    "LANGS = {\n",
    "    \"한국어\": \"ko\",\n",
    "    \"영어\": \"en\",\n",
    "    \"일본어\": \"ja\",\n",
    "    \"중국어(간체)\": \"zh\",\n",
    "    \"스페인어\": \"es\",\n",
    "    \"프랑스어\": \"fr\"\n",
    "}\n",
    "\n",
    "# 3. 번역 함수 정의\n",
    "\n",
    "def translate(text: str, src_lang: str, tgt_lang: str) -> str:\n",
    "    \"\"\"\n",
    "    text: 번역할 문장\n",
    "    src_lang: 입력 언어 코드 (ex: 'ko')\n",
    "    tgt_lang: 출력 언어 코드 (ex: 'en')\n",
    "    \"\"\"\n",
    "    tokenizer.src_lang = src_lang\n",
    "    encoded = tokenizer(text, return_tensors=\"pt\")\n",
    "    generated = model.generate(\n",
    "        **encoded,\n",
    "        forced_bos_token_id=tokenizer.get_lang_id(tgt_lang)\n",
    "    )\n",
    "    return tokenizer.batch_decode(generated, skip_special_tokens=True)[0]\n",
    "\n",
    "# 4. Gradio 인터페이스\n",
    "\n",
    "def build_interface():\n",
    "    # 입력 컴포넌트 설정\n",
    "    txt = gr.Textbox(lines=3, placeholder=\"번역할 텍스트를 입력하세요\", label=\"원문\")\n",
    "    src = gr.Dropdown(choices=list(LANGS.keys()), label=\"원문 언어\", value=\"한국어\")\n",
    "    tgt = gr.Dropdown(choices=list(LANGS.keys()), label=\"목표 언어\", value=\"영어\")\n",
    "    output = gr.Textbox(label=\"번역 결과\")\n",
    "\n",
    "    # 인터페이스 생성\n",
    "    iface = gr.Interface(\n",
    "        fn=lambda text, s, t: translate(text, LANGS[s], LANGS[t]),\n",
    "        inputs=[txt, src, tgt],\n",
    "        outputs=output,\n",
    "        title=\"📖 다국어 번역기\",\n",
    "        description=\"facebook/m2m100_418M 모델 기반 간편 다국어 번역 서비스\"\n",
    "    )\n",
    "    return iface\n",
    "\n",
    "# 5. 데모 실행\n",
    "if __name__ == \"__main__\":\n",
    "    demo = build_interface()\n",
    "    # 로컬 실행 및 외부 공유 활성화\n",
    "    demo.launch(share=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a6659e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "22838e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install datasets\n",
    "# !pip install soundfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4fbe5f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\miniforge3\\envs\\ai_seving\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Admin\\.cache\\huggingface\\hub\\models--microsoft--speecht5_tts. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\Admin\\miniforge3\\envs\\ai_seving\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Admin\\.cache\\huggingface\\hub\\models--microsoft--speecht5_hifigan. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\Admin\\miniforge3\\envs\\ai_seving\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Admin\\.cache\\huggingface\\hub\\datasets--Matthijs--cmu-arctic-xvectors. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Generating validation split: 100%|███████████████████████████████████████| 7931/7931 [00:00<00:00, 56489.88 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import SpeechT5Processor, SpeechT5ForTextToSpeech, SpeechT5HifiGan\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "import soundfile as sf\n",
    "from datasets import load_dataset\n",
    "\n",
    "processor = SpeechT5Processor.from_pretrained(\"microsoft/speecht5_tts\")\n",
    "model = SpeechT5ForTextToSpeech.from_pretrained(\"microsoft/speecht5_tts\")\n",
    "vocoder = SpeechT5HifiGan.from_pretrained(\"microsoft/speecht5_hifigan\")\n",
    "\n",
    "inputs = processor(text=\"Hello, my dog is cute.\", return_tensors=\"pt\")\n",
    "\n",
    "# load xvector containing speaker's voice characteristics from a dataset\n",
    "embeddings_dataset = load_dataset(\"Matthijs/cmu-arctic-xvectors\", split=\"validation\")\n",
    "speaker_embeddings = torch.tensor(embeddings_dataset[7306][\"xvector\"]).unsqueeze(0)\n",
    "\n",
    "speech = model.generate_speech(inputs[\"input_ids\"], speaker_embeddings, vocoder=vocoder)\n",
    "\n",
    "sf.write(\"speech.wav\", speech.numpy(), samplerate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "31000746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "* Running on public URL: https://7f7fecc1c5668ee1ba.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://7f7fecc1c5668ee1ba.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\miniforge3\\envs\\ai_seving\\Lib\\site-packages\\gradio\\processing_utils.py:753: UserWarning: Trying to convert audio automatically from float32 to 16-bit int format.\n",
      "  warnings.warn(warning.format(data.dtype))\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "📖 다국어 번역기 + 읽어주기 기능 (Gradio + M2M100 + SpeechT5)\n",
    "- transformers의 facebook/m2m100_418M 모델로 번역\n",
    "- microsoft/speecht5_tts 모델로 영어 TTS\n",
    "- Gradio로 웹 UI 구성\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import soundfile as sf\n",
    "import gradio as gr\n",
    "from transformers import M2M100ForConditionalGeneration, M2M100Tokenizer\n",
    "from transformers import SpeechT5Processor, SpeechT5ForTextToSpeech, SpeechT5HifiGan\n",
    "from datasets import load_dataset\n",
    "\n",
    "# 1. 모델 및 토크나이저 초기화\n",
    "model_mt = M2M100ForConditionalGeneration.from_pretrained(\"facebook/m2m100_418M\")\n",
    "tokenizer_mt = M2M100Tokenizer.from_pretrained(\"facebook/m2m100_418M\")\n",
    "processor_tts = SpeechT5Processor.from_pretrained(\"microsoft/speecht5_tts\")\n",
    "model_tts = SpeechT5ForTextToSpeech.from_pretrained(\"microsoft/speecht5_tts\")\n",
    "vocoder_tts = SpeechT5HifiGan.from_pretrained(\"microsoft/speecht5_hifigan\")\n",
    "\n",
    "# 2. 지원 언어 매핑\n",
    "LANGS = {\n",
    "    \"한국어\": \"ko\",\n",
    "    \"영어\": \"en\",\n",
    "    \"일본어\": \"ja\",\n",
    "    \"중국어(간체)\": \"zh\",\n",
    "    \"스페인어\": \"es\",\n",
    "    \"프랑스어\": \"fr\"\n",
    "}\n",
    "\n",
    "# 3. 스피커 임베딩 로드 (예시용)\n",
    "emb_ds = load_dataset(\"Matthijs/cmu-arctic-xvectors\", split=\"validation\")\n",
    "speaker_embedding = torch.tensor(emb_ds[7306][\"xvector\"]).unsqueeze(0)\n",
    "\n",
    "# 4. 번역 및 TTS 함수 정의\n",
    "\n",
    "def translate_and_tts(text: str, src_lang_label: str, tgt_lang_label: str):\n",
    "    # 레이블을 언어 코드로 변환\n",
    "    src_code = LANGS[src_lang_label]\n",
    "    tgt_code = LANGS[tgt_lang_label]\n",
    "\n",
    "    # 번역\n",
    "    tokenizer_mt.src_lang = src_code\n",
    "    encoded = tokenizer_mt(text, return_tensors=\"pt\")\n",
    "    gen = model_mt.generate(\n",
    "        **encoded,\n",
    "        forced_bos_token_id=tokenizer_mt.get_lang_id(tgt_code)\n",
    "    )\n",
    "    translated = tokenizer_mt.batch_decode(gen, skip_special_tokens=True)[0]\n",
    "\n",
    "    # 영어일 경우 TTS 생성\n",
    "    audio_data = None\n",
    "    if tgt_code == \"en\":\n",
    "        inputs_tts = processor_tts(text=translated, return_tensors=\"pt\")\n",
    "        speech = model_tts.generate_speech(\n",
    "            inputs_tts[\"input_ids\"], speaker_embedding, vocoder=vocoder_tts\n",
    "        )\n",
    "        audio_data = speech.cpu().numpy()\n",
    "\n",
    "    # 반환 형식: (번역문, (샘플레이트, 오디오) or None)\n",
    "    return translated, (16000, audio_data) if audio_data is not None else None\n",
    "\n",
    "# 5. Gradio 인터페이스 구축\n",
    "\n",
    "def build_interface():\n",
    "    txt = gr.Textbox(lines=3, placeholder=\"번역할 텍스트 입력\", label=\"원문\")\n",
    "    src = gr.Dropdown(choices=list(LANGS.keys()), label=\"원문 언어\", value=\"한국어\")\n",
    "    tgt = gr.Dropdown(choices=list(LANGS.keys()), label=\"목표 언어\", value=\"영어\")\n",
    "    out_txt = gr.Textbox(label=\"번역 결과\")\n",
    "    out_audio = gr.Audio(label=\"읽어주기 (영어)\")\n",
    "\n",
    "    iface = gr.Interface(\n",
    "        fn=translate_and_tts,\n",
    "        inputs=[txt, src, tgt],\n",
    "        outputs=[out_txt, out_audio],\n",
    "        title=\"📖 다국어 번역기 + 읽어주기\",\n",
    "        description=\"번역 및 영어에 한해 TTS(읽어주기) 기능을 제공합니다.\"\n",
    "    )\n",
    "    return iface\n",
    "\n",
    "# 6. 데모 실행\n",
    "if __name__ == \"__main__\":\n",
    "    demo = build_interface()\n",
    "    demo.launch(share=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb15a21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fe4a7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60122b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970b8d70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5633736",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac1ff42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a18d5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79918a62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98534c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd524c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edacf8d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
